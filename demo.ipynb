{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Skovorp/Homemade-Torch/\n",
        "%cd Homemade-Torch"
      ],
      "metadata": {
        "id": "uyWKwb9hk1Rm",
        "outputId": "6f55171d-9899-4ccd-a56d-49defbed942c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uyWKwb9hk1Rm",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Homemade-Torch' already exists and is not an empty directory.\n",
            "/content/Homemade-Torch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lonely-delta",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "lonely-delta"
      },
      "source": [
        "# Глубинное обучение 1 / Введение в глубинное обучение, ФКН ВШЭ\n",
        "\n",
        "## Домашнее задание 1. Часть 1: автоматическое дифференцирование.\n",
        "\n",
        "### Общая информация\n",
        "\n",
        "Оценка после штрафа после мягкого дедлайна вычисляется по формуле $M_{\\text{penalty}} = M_{\\text{full}} \\cdot 0.85^{t/1440}$, где $M_{\\text{full}}$ — полная оценка за работу без учета штрафа, а $t$ — время в минутах, прошедшее после мягкого дедлайна (округление до двух цифр после запятой). Таким образом, спустя первые сутки после мягкого дедлайна вы не можете получить оценку выше 8.5, а если сдать через четыре дня после мягкого дедлайна, то ваш максимум — 5.22 балла.\n",
        "\n",
        "### Оценивание и штрафы\n",
        "\n",
        "Максимально допустимая оценка за работу — 10 баллов. Сдавать задание после указанного срока сдачи нельзя.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке. Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
        "\n",
        "### О задании\n",
        "\n",
        "В этом задании вам предстоит реализовать свой фреймворк для обучения нейронных сетей на основе `numpy`. Интерфейс фреймворка будет максимально копировать PyTorch, так что вы немного познакомитесь с тем, как все устроено изнутри. Директория `modules` содержит файлы с шаблонами фреймровка, а `tests` &mdash; тесты для проверки корректности ваших реализаций.\n",
        "\n",
        "Ячейка ниже повзоляет переподгружать питоновские модули, которые вы изменили после импорта, без необходимости перезапускать ноубук."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "suspended-death",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "suspended-death"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "lonely-component",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lonely-component"
      },
      "outputs": [],
      "source": [
        "import tests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "optimum-mechanics",
      "metadata": {
        "id": "optimum-mechanics"
      },
      "source": [
        "## 0. Автоматическое дифференцирование\n",
        "\n",
        "Самый главным объектом в нашем фреймворке будет абстракция слоя (класс `Module`), которая реализована в файле `modules/base.py`. Перед тем как писать свой код, ознакомьтесь с реализацией класса `Module`. Каждый слой должен поддерживать две операции: проход вперед, который принимает выход предыдущего слоя и вычисляет функцию слоя, и проход назад, который принимает выход предыдущего слоя и производную по своему выходу, а возвращает производную по входу, попутно обновляя градиент по своим параметрам. Вспомним общую схему еще раз. Пусть $f(x, w)$ &mdash; это наша функция слоя, которая зависит от входа $x$ и параметров в $w$, $\\ell$ - функция потерь, градиент по параметрам которой нас интересует. Тогда:\n",
        "\n",
        "- Проход вперед:\n",
        "\n",
        "$$y = f(x, w)$$\n",
        "\n",
        "- Проход назад:\n",
        "\n",
        "$$\\frac{d\\ell}{dx} = \\frac{d\\ell}{dy} \\cdot \\frac{df(x, w)}{dx}$$\n",
        "\n",
        "$$\\frac{d\\ell}{dw} = \\frac{d\\ell}{dy} \\cdot \\frac{df(x, w)}{dw}$$\n",
        "\n",
        "Таким образом, при проходе вперед в слой передается $x$, при проходе назад $x$ и $\\frac{d\\ell}{dy}$. Кроме того, каждый слой сохраняет свой выход при проходе вперед, чтобы затем передать его в следующий слой при проходе назад. Сответственно, базовый класс `Module` реализует функции `forward` (или его alias, метод `__call__`, аналогично тому, как это сделано в PyTorch) и `backward`. Кроме того, шаблоны содержат некоторые служебные функции, в том числе `train` и `eval`, которые меняют режим слоя. Все слои, которые вам нужно реализовать, будут наследоваться от класса `Module`. В них потребуется реализовать методы `compute_output`, `compute_grad_input` и `update_grad_parameters` (если у слоя есть обучаемые параметры). За подробностями обращайтесь к док-строкам в шаблонах. Мы будем реализовывать слои аналогично соответствующим слоям из PyTorch, поэтому можете сверяться с документацией для уточнения значений параметров слоев. Для вашего удобства мы приводим тесты для отладки реализаций, ваше решение должно их проходить (баллы начисляются за пройденные тесты). В случае возникновения затруднений советуем дебажить код, сравнивая вашу реализацию с модулями из PyTorch.\n",
        "\n",
        "**Важно:** мы хотим получить такое же поведение, как у PyTorch, поэтому если сделать несколько проходов назад без вызова функции `zero_grad`, то градиенты со всех проходов назад должны суммироваться. Это значит, что в функции `update_grad_parameters` нужно прибавить новый градиент к уже имеющемуся, а не перезаписать его.\n",
        "\n",
        "Обратите внимание, что все ваши подсчеты функций и градиентов должны быть **векторизованными**, то есть включать только операции на `numpy`/`scipy` и **никаких питоновских циклов** (или оберток над ними из указанных библиотек). Специальные места, в которых циклы разрешены, будут указаны отдельно."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "traditional-vietnam",
      "metadata": {
        "id": "traditional-vietnam"
      },
      "source": [
        "## 1. Линейный слой (1 балл)\n",
        "\n",
        "- Прототип: [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
        "- Расположение: `modules.layers.Linear`\n",
        "\n",
        "Отныне мы будем иметь в виду, что вход нейросети $x$ имеет размер $B \\times N$, где $B$ &mdash; размер мини-батча, а $N$ &mdash; размерность. Функция слоя выглядит как:\n",
        "\n",
        "$$\n",
        "y = x \\, W^T + b,\n",
        "$$\n",
        "\n",
        "где $W \\in \\mathbb{R}^{M \\times N}, b \\in \\mathbb{R}^M$. Таким образом, выход слоя имеет размер $B \\times M$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "hired-modem",
      "metadata": {
        "id": "hired-modem",
        "outputId": "b1eb9404-de00-477c-ada5-8d86b5fd3097",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_linear ... Input shape: (64, 16), bias: False\n",
            "Input shape: (64, 16), bias: True\n",
            "Input shape: (128, 32), bias: False\n",
            "Input shape: (128, 32), bias: True\n",
            "Input shape: (256, 64), bias: False\n",
            "Input shape: (256, 64), bias: True\n",
            "OK\n"
          ]
        }
      ],
      "source": [
        "tests.test_linear()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "improving-satellite",
      "metadata": {
        "id": "improving-satellite"
      },
      "source": [
        "## 2. Batch-нормализация (2.5 балла)\n",
        "\n",
        "- Прототип: [nn.BatchNorm1d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html#torch.nn.BatchNorm1d)\n",
        "- Расположение: `modules.layers.BatchNormalization`\n",
        "\n",
        "Batch-нормализация &mdash; первый слой, который работает по-разному в train и eval режимах.\n",
        "\n",
        "**Режим train:**\n",
        "\n",
        "1. Для каждой координаты входа считаем статистики по мини-батчу ($x_i \\in \\mathbb{R}^N$ &mdash; один объект в мини-батче):\n",
        "\n",
        "$$\n",
        "\\mu = \\frac{1}{B} \\sum_{i=1}^B x_i, \\quad\\quad \\mu \\in \\mathbb{R}^N \\\\\n",
        "\\sigma^2 = \\frac{1}{B} \\sum_{i=1}^B (x_i - \\mu)^2, \\quad\\quad \\sigma^2 \\in \\mathbb{R}^N\n",
        "$$\n",
        "\n",
        "Обратите внимание, что здесь используется **смещенная** оценка дисперсии (то есть мы делим сумму квадратов отклонений на $B$, а не на $B-1$).\n",
        "\n",
        "2. Нормируем вход с учетом статистик:\n",
        "\n",
        "$$\n",
        "\\hat{x}_i = \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\varepsilon}}\n",
        "$$\n",
        "\n",
        "3. Применяем афинное преобразование к нормированному входу (если `affine = True`), умножение поэлементное. Это и будет выход слоя.\n",
        "\n",
        "$$\n",
        "y_i = \\hat{x}_i * w + b, \\quad\\quad w, b \\in \\mathbb{R}^N\n",
        "$$\n",
        "\n",
        "4. Обновляем бегущие статистики слоя:\n",
        "\n",
        "$$\n",
        "\\text{running_mean} = (1 - \\text{momentum}) \\cdot \\text{running_mean} + \\text{momentum} \\cdot \\mu \\\\\n",
        "\\text{running_var} = (1 - \\text{momentum}) \\cdot \\text{running_var} + \\text{momentum} \\cdot \\frac{B}{B - 1}\n",
        "\\cdot \\sigma^2\n",
        "$$\n",
        "\n",
        "Здесь перенормировка $\\sigma^2$ необходима, чтобы обновлять бегущую дисперсию **несмещенной** оценкой (точно так же это реализовано в PyTorch).\n",
        "\n",
        "К параметрам слоя, которые обновляются градиентом, относятся только $w$ (`weight`) и $b$ (`bias`), но не `running_mean` и `running_var`.\n",
        "\n",
        "**Режим eval:**\n",
        "\n",
        "1. Нормируем вход, используя бегущие статистики:\n",
        "\n",
        "$$\n",
        "\\hat{x}_i = \\frac{x_i - \\text{running_mean}}{\\sqrt{\\text{running_var} + \\varepsilon}}\n",
        "$$\n",
        "\n",
        "2. Применяем афинное преобразование к нормированному входу:\n",
        "\n",
        "$$\n",
        "y_i = \\hat{x}_i * w + b\n",
        "$$\n",
        "\n",
        "**Хозяйке на заметку**\n",
        "\n",
        "- Убедитесь, что проход назад корректно работает и для train, и для eval режимов\n",
        "- Сохраняйте промежуточные вычисления при проходе вперед, чтобы переиспользовать их при проходе назад\n",
        "- Весьма вероятно, что у вас не получится правильная реализация с первого раза. Не отчаивайтесь, автор задания тоже потратил не один час, пока этот модуль не заработал. Если чувствуете, что зашли в тупик, то пользоваться гуглом никто не запрещал, но не забудьте указать источники, которыми пользуетесь."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "every-prison",
      "metadata": {
        "id": "every-prison",
        "outputId": "a30a182a-0b6e-4c3f-a956-dd3a0418bdbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_bn ... !!! momentum: 0.1, input_shape: (64, 16), affine: False, eval_module: False\n",
            "!!! momentum: 0.1, input_shape: (64, 16), affine: False, eval_module: True\n",
            "!!! momentum: 0.1, input_shape: (64, 16), affine: True, eval_module: False\n",
            "!!! momentum: 0.1, input_shape: (64, 16), affine: True, eval_module: True\n",
            "!!! momentum: 0.5, input_shape: (128, 32), affine: False, eval_module: False\n",
            "!!! momentum: 0.5, input_shape: (128, 32), affine: False, eval_module: True\n",
            "!!! momentum: 0.5, input_shape: (128, 32), affine: True, eval_module: False\n",
            "!!! momentum: 0.5, input_shape: (128, 32), affine: True, eval_module: True\n",
            "!!! momentum: 0.9, input_shape: (256, 64), affine: False, eval_module: False\n",
            "!!! momentum: 0.9, input_shape: (256, 64), affine: False, eval_module: True\n",
            "!!! momentum: 0.9, input_shape: (256, 64), affine: True, eval_module: False\n",
            "!!! momentum: 0.9, input_shape: (256, 64), affine: True, eval_module: True\n",
            "OK\n"
          ]
        }
      ],
      "source": [
        "tests.test_bn()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "successful-dover",
      "metadata": {
        "id": "successful-dover"
      },
      "source": [
        "## 3. Dropout (1 балл)\n",
        "\n",
        "- Прототип: [nn.Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout)\n",
        "- Расположение: `modules.layers.Dropout`\n",
        "\n",
        "Dropout &mdash; еще один слой, чье поведение различно в train и eval режимах. Поведения слоя регулируется параметром $p$ &mdash; вероятностью занулить координату входа.\n",
        "\n",
        "**Режим train:**\n",
        "\n",
        "Обозначим за $m$ бинарную маску, имеющую такой же размер, как вход $x$. Маска генерируется по правилу $m_{ij} \\sim \\text{Bernoulli}(1-p)$. При этом при каждом новом проходе вперед генерируется новая маска (то есть она не фиксирована). Функция слоя (умножение поэлементное):\n",
        "\n",
        "$$\n",
        "y = \\frac{1}{1-p} m * x\n",
        "$$\n",
        "\n",
        "Нормализация на $1-p$ необходима, чтобы среднее значение нейронов входа не изменилось.\n",
        "\n",
        "**Режим eval:**\n",
        "\n",
        "Здесь все предельно просто: вход слоя никаких не изменяется $y=x$.\n",
        "\n",
        "**Хозяйке на заметку**\n",
        "\n",
        "- Убедитесь, что проход назад корректно работает и для train, и для eval режимов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "collective-western",
      "metadata": {
        "id": "collective-western",
        "outputId": "3e5a8450-19fd-447e-f0bd-669d9add5856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_dropout ... OK\n"
          ]
        }
      ],
      "source": [
        "tests.test_dropout()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "appointed-metropolitan",
      "metadata": {
        "id": "appointed-metropolitan"
      },
      "source": [
        "## 4. Функции активации (1.5 балла)\n",
        "\n",
        "### ReLU\n",
        "\n",
        "- Прототип: [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)\n",
        "- Расположение: `modules.activations.ReLU`\n",
        "\n",
        "Функция слоя:\n",
        "\n",
        "$$\n",
        "y = \\max(x, 0)\n",
        "$$\n",
        "\n",
        "### Sigmoid\n",
        "\n",
        "- Прототип: [nn.Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html?highlight=nn%20sigmoid#torch.nn.Sigmoid)\n",
        "- Расположение: `modules.activations.Sigmoid`\n",
        "\n",
        "Функция слоя:\n",
        "\n",
        "$$\n",
        "y = \\frac{1}{1 + e^{-x}}\n",
        "$$\n",
        "\n",
        "### Softmax\n",
        "\n",
        "- Прототип: [nn.Softmax](http://bit.ly/get3a)\n",
        "- Расположение: `modules.activations.Softmax`\n",
        "\n",
        "Функция слоя:\n",
        "\n",
        "$$\n",
        "y_{ij} = \\frac{\\exp(x_{ij})}{\\sum_{k=1}^{N} \\exp(x_{ik})}\n",
        "$$\n",
        "\n",
        "### LogSoftmax\n",
        "\n",
        "- Прототип: [nn.LogSoftmax](https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html?highlight=log%20softmax#torch.nn.LogSoftmax)\n",
        "- Расположение: `modules.activations.LogSoftmax`\n",
        "\n",
        "Функция слоя:\n",
        "\n",
        "$$\n",
        "y_{ij} = \\log \\left(\\frac{\\exp(x_{ij})}{\\sum_{k=1}^{N} \\exp(x_{ik})}\\right)\n",
        "$$\n",
        "\n",
        "**Хозяйке на заметку**\n",
        "\n",
        "- Пользуйтесь функциями из `scipy.special`\n",
        "- Реализовывать `LogSoftmax` как логарифм от модуля `Softmax` &mdash; плохая идея"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "great-sector",
      "metadata": {
        "id": "great-sector",
        "outputId": "9ec209b7-3281-4772-fd03-51aa71df4b8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_activations ... OK\n"
          ]
        }
      ],
      "source": [
        "tests.test_activations()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "disabled-proof",
      "metadata": {
        "id": "disabled-proof"
      },
      "source": [
        "## 5. Контейнер Sequential (1 балл)\n",
        "\n",
        "- Прототип: [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)\n",
        "- Расположение: `modules.layers.Sequential`\n",
        "\n",
        "Контейнер-обертка, который применяет слои последовательно.\n",
        "\n",
        "**Важно:** здесь разрешен цикл по модулям при проходах вперед и назад."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "standard-electron",
      "metadata": {
        "id": "standard-electron",
        "outputId": "c7bf232c-7cca-4d06-d2e3-9f5a3065903b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_sequential ... OK\n"
          ]
        }
      ],
      "source": [
        "tests.test_sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "extensive-mirror",
      "metadata": {
        "id": "extensive-mirror"
      },
      "source": [
        "## 6. Функции потерь (1 балл)\n",
        "\n",
        "Функции потерь отличаются от всех остальных модулей тем, что являются стоком вычислительного графа (то есть из них нет исходящих операций). Это означает, что с них начинается проход назад, поэтому интерфейс функции `compute_grad_input` выглядит иначе: вместо входа модуля и производной по выходу в функцию приходит предсказание нейронной сети (производная по которому нас и интересует, чтобы запустить проход назад) и целевая переменная. Базовый класс для всех функций потерь &mdash; `modules.base.Criterion`.\n",
        "\n",
        "### MSE\n",
        "\n",
        "- Прототип: [nn.MSELoss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss)\n",
        "- Расположение: `modules.criterions.MSELoss`\n",
        "\n",
        "Пусть $f \\in \\mathbb{R}^{B\\times N}$ &mdash; предсказание нейронной сети, а $y \\in \\mathbb{R}^{B\\times N}$ &mdash; целевая переменная. Функция потерь выглядит как:\n",
        "\n",
        "$$\n",
        "\\ell(f, y) = \\frac{1}{BN} \\sum_{i=1}^B \\sum_{j=1}^N (f_{ij} - y_{ij})^2\n",
        "$$\n",
        "\n",
        "### Cross Entropy\n",
        "\n",
        "- Прототип: [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)\n",
        "- Расположение: `modules.criterions.CrossEntropyLoss`\n",
        "\n",
        "Кросс-энтропия &mdash; это функция потерь для обучения классификаторов. Пусть $f \\in \\mathbb{R}^{B\\times C}$ (где $C$ &mdash; число классов) &mdash; предсказание нейронной сети (это так называемые *логиты*, обычно выходы линейного слоя без активации, потому могут быть любыми вещественными числами), а $y \\in \\{1, \\dots, C\\}^B$ &mdash; целевая переменная (номер класса соответствующего объекта). Функция потерь вычисляется как:\n",
        "\n",
        "$$\n",
        "p_{ic} = \\frac{\\exp(f_{ic})}{\\sum_{k=1}^C \\exp(f_{ik})}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\ell(f, y) = -\\frac{1}{B} \\sum_{i=1}^B \\sum_{c=1}^C [c = y_i] \\log p_{ic}\n",
        "$$\n",
        "\n",
        "При этом, $p_{ic}$ &mdash; это вероятность класса $с$ для объекта $i$, которую предсказывает нейронная сеть.\n",
        "\n",
        "**Важно:** вычисление Softmax, а затем логарифма от него &mdash; численно нестабильная операция. Воспользуйтесь слоем LogSoftmax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "early-hampshire",
      "metadata": {
        "id": "early-hampshire",
        "outputId": "64e1ab20-40c8-4b21-b0c5-dd73f9e5de4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_criterions ... OK\n"
          ]
        }
      ],
      "source": [
        "tests.test_criterions()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "steady-edition",
      "metadata": {
        "id": "steady-edition"
      },
      "source": [
        "## 7. Оптимизаторы (1.5 балла)\n",
        "\n",
        "Оптимизатор &mdash; вспомогательный класс, который обновляет веса нейронной сети при градиентном спуске, используя сохраненные градиенты параметров. Базовый класс &mdash; `modules.base.Optimizer`. В документации PyTorch приведен псевдокод с описанием алгоритмов, советуем обратиться туда.\n",
        "\n",
        "**Важно:** здесь разрешен цикл по параметрам и градиентам (см. шаблоны)\n",
        "\n",
        "### SGD\n",
        "\n",
        "- Прототип: [torch.optim.SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html)\n",
        "- Расположение: `modules.optimizers.SGD`\n",
        "\n",
        "### Adam\n",
        "\n",
        "- Прототип: [torch.optim.Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)\n",
        "- Расположение: `modules.criterions.CrossEntropyLoss`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "selected-cuisine",
      "metadata": {
        "id": "selected-cuisine",
        "outputId": "66d64fd0-6944-4701-9995-b3a1eca08e13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_optimizers ... OK\n"
          ]
        }
      ],
      "source": [
        "tests.test_optimizers()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "centered-therapist",
      "metadata": {
        "id": "centered-therapist"
      },
      "source": [
        "## 8. DataLoader (0.5 балла)\n",
        "\n",
        "- Прототип: [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n",
        "- Расположение: `modules.dataloader.DataLoader`\n",
        "\n",
        "И последнее, что нам осталось реализовать &mdash; это DataLoader, который перемешивает данные раз в эпоху (если это необходимо) и формирует из них мини-батчи. Технически, это будет питоновский итератор. Вот краткое [руководство](https://stackoverflow.com/questions/19151/how-to-build-a-basic-iterator), как написать итератор.\n",
        "\n",
        "Обратите внимание, что ваша реализация должна уметь работать как с одномерным массивом целевой переменной (с формой `(num_samples, )` &mdash; так будет удобнее учить нейронную сеть на кросс-энтропию), так и с двумерной версией (с формой`(num_samples, 1)` &mdash; сответственно, на MSE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ready-trance",
      "metadata": {
        "id": "ready-trance",
        "outputId": "affa6263-4e5a-4a02-99de-3ba61cb881dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_dataloader ... data shape: (100, 20) batch_size: 1 shuffle: False unsqueezed_y: False\n",
            "data shape: (100, 20) batch_size: 1 shuffle: False unsqueezed_y: True\n",
            "data shape: (100, 20) batch_size: 1 shuffle: True unsqueezed_y: False\n",
            "data shape: (100, 20) batch_size: 1 shuffle: True unsqueezed_y: True\n",
            "data shape: (100, 20) batch_size: 16 shuffle: False unsqueezed_y: False\n",
            "data shape: (100, 20) batch_size: 16 shuffle: False unsqueezed_y: True\n",
            "data shape: (100, 20) batch_size: 16 shuffle: True unsqueezed_y: False\n",
            "data shape: (100, 20) batch_size: 16 shuffle: True unsqueezed_y: True\n",
            "data shape: (100, 20) batch_size: 100 shuffle: False unsqueezed_y: False\n",
            "data shape: (100, 20) batch_size: 100 shuffle: False unsqueezed_y: True\n",
            "data shape: (100, 20) batch_size: 100 shuffle: True unsqueezed_y: False\n",
            "data shape: (100, 20) batch_size: 100 shuffle: True unsqueezed_y: True\n",
            "data shape: (100, 20) batch_size: 500 shuffle: False unsqueezed_y: False\n",
            "data shape: (100, 20) batch_size: 500 shuffle: False unsqueezed_y: True\n",
            "data shape: (100, 20) batch_size: 500 shuffle: True unsqueezed_y: False\n",
            "data shape: (100, 20) batch_size: 500 shuffle: True unsqueezed_y: True\n",
            "data shape: (100, 20) batch_size: 512 shuffle: False unsqueezed_y: False\n",
            "data shape: (100, 20) batch_size: 512 shuffle: False unsqueezed_y: True\n",
            "data shape: (100, 20) batch_size: 512 shuffle: True unsqueezed_y: False\n",
            "data shape: (100, 20) batch_size: 512 shuffle: True unsqueezed_y: True\n",
            "data shape: (100, 20) batch_size: 1000 shuffle: False unsqueezed_y: False\n",
            "data shape: (100, 20) batch_size: 1000 shuffle: False unsqueezed_y: True\n",
            "data shape: (100, 20) batch_size: 1000 shuffle: True unsqueezed_y: False\n",
            "data shape: (100, 20) batch_size: 1000 shuffle: True unsqueezed_y: True\n",
            "data shape: (1000, 100) batch_size: 1 shuffle: False unsqueezed_y: False\n",
            "data shape: (1000, 100) batch_size: 1 shuffle: False unsqueezed_y: True\n",
            "data shape: (1000, 100) batch_size: 1 shuffle: True unsqueezed_y: False\n",
            "data shape: (1000, 100) batch_size: 1 shuffle: True unsqueezed_y: True\n",
            "data shape: (1000, 100) batch_size: 16 shuffle: False unsqueezed_y: False\n",
            "data shape: (1000, 100) batch_size: 16 shuffle: False unsqueezed_y: True\n",
            "data shape: (1000, 100) batch_size: 16 shuffle: True unsqueezed_y: False\n",
            "data shape: (1000, 100) batch_size: 16 shuffle: True unsqueezed_y: True\n",
            "data shape: (1000, 100) batch_size: 100 shuffle: False unsqueezed_y: False\n",
            "data shape: (1000, 100) batch_size: 100 shuffle: False unsqueezed_y: True\n",
            "data shape: (1000, 100) batch_size: 100 shuffle: True unsqueezed_y: False\n",
            "data shape: (1000, 100) batch_size: 100 shuffle: True unsqueezed_y: True\n",
            "data shape: (1000, 100) batch_size: 500 shuffle: False unsqueezed_y: False\n",
            "data shape: (1000, 100) batch_size: 500 shuffle: False unsqueezed_y: True\n",
            "data shape: (1000, 100) batch_size: 500 shuffle: True unsqueezed_y: False\n",
            "data shape: (1000, 100) batch_size: 500 shuffle: True unsqueezed_y: True\n",
            "data shape: (1000, 100) batch_size: 512 shuffle: False unsqueezed_y: False\n",
            "data shape: (1000, 100) batch_size: 512 shuffle: False unsqueezed_y: True\n",
            "data shape: (1000, 100) batch_size: 512 shuffle: True unsqueezed_y: False\n",
            "data shape: (1000, 100) batch_size: 512 shuffle: True unsqueezed_y: True\n",
            "data shape: (1000, 100) batch_size: 1000 shuffle: False unsqueezed_y: False\n",
            "data shape: (1000, 100) batch_size: 1000 shuffle: False unsqueezed_y: True\n",
            "data shape: (1000, 100) batch_size: 1000 shuffle: True unsqueezed_y: False\n",
            "data shape: (1000, 100) batch_size: 1000 shuffle: True unsqueezed_y: True\n",
            "data shape: (10000, 500) batch_size: 1 shuffle: False unsqueezed_y: False\n",
            "data shape: (10000, 500) batch_size: 1 shuffle: False unsqueezed_y: True\n",
            "data shape: (10000, 500) batch_size: 1 shuffle: True unsqueezed_y: False\n",
            "data shape: (10000, 500) batch_size: 1 shuffle: True unsqueezed_y: True\n",
            "data shape: (10000, 500) batch_size: 16 shuffle: False unsqueezed_y: False\n",
            "data shape: (10000, 500) batch_size: 16 shuffle: False unsqueezed_y: True\n",
            "data shape: (10000, 500) batch_size: 16 shuffle: True unsqueezed_y: False\n",
            "data shape: (10000, 500) batch_size: 16 shuffle: True unsqueezed_y: True\n",
            "data shape: (10000, 500) batch_size: 100 shuffle: False unsqueezed_y: False\n",
            "data shape: (10000, 500) batch_size: 100 shuffle: False unsqueezed_y: True\n",
            "data shape: (10000, 500) batch_size: 100 shuffle: True unsqueezed_y: False\n",
            "data shape: (10000, 500) batch_size: 100 shuffle: True unsqueezed_y: True\n",
            "data shape: (10000, 500) batch_size: 500 shuffle: False unsqueezed_y: False\n",
            "data shape: (10000, 500) batch_size: 500 shuffle: False unsqueezed_y: True\n",
            "data shape: (10000, 500) batch_size: 500 shuffle: True unsqueezed_y: False\n",
            "data shape: (10000, 500) batch_size: 500 shuffle: True unsqueezed_y: True\n",
            "data shape: (10000, 500) batch_size: 512 shuffle: False unsqueezed_y: False\n",
            "data shape: (10000, 500) batch_size: 512 shuffle: False unsqueezed_y: True\n",
            "data shape: (10000, 500) batch_size: 512 shuffle: True unsqueezed_y: False\n",
            "data shape: (10000, 500) batch_size: 512 shuffle: True unsqueezed_y: True\n",
            "data shape: (10000, 500) batch_size: 1000 shuffle: False unsqueezed_y: False\n",
            "data shape: (10000, 500) batch_size: 1000 shuffle: False unsqueezed_y: True\n",
            "data shape: (10000, 500) batch_size: 1000 shuffle: True unsqueezed_y: False\n",
            "data shape: (10000, 500) batch_size: 1000 shuffle: True unsqueezed_y: True\n",
            "OK\n"
          ]
        }
      ],
      "source": [
        " tests.test_dataloader()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "active-algorithm",
      "metadata": {
        "id": "active-algorithm"
      },
      "source": [
        "## Bringing it all togeter\n",
        "\n",
        "If you did everything right, following code training a network should work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "innovative-fetish",
      "metadata": {
        "id": "innovative-fetish"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import modules as mm\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "super-latest",
      "metadata": {
        "id": "super-latest"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "X_train = np.random.randn(2048, 8)\n",
        "X_test = np.random.randn(512, 8)\n",
        "y_train = np.sin(X_train).sum(axis=1, keepdims=True)\n",
        "y_test = np.sin(X_test).sum(axis=1, keepdims=True)\n",
        "\n",
        "train_loader = mm.DataLoader(X_train, y_train, batch_size=64, shuffle=True)\n",
        "test_loader = mm.DataLoader(X_test, y_test, batch_size=64, shuffle=False)\n",
        "\n",
        "model = mm.Sequential(\n",
        "    mm.Linear(8, 32),\n",
        "    mm.BatchNormalization(32),\n",
        "    mm.ReLU(),\n",
        "    mm.Linear(32, 64),\n",
        "    mm.Dropout(0.25),\n",
        "    mm.Sigmoid(),\n",
        "    mm.Linear(64, 1)\n",
        ")\n",
        "optimizer = mm.Adam(model, lr=1e-2)\n",
        "criterion = mm.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "gothic-latin",
      "metadata": {
        "id": "gothic-latin",
        "outputId": "7596af23-252b-4899-b042-f21b5a6b10de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "15333d704d3c48e5ae680c9a31eeec57",
            "01a04f17987642efa7f8c37c0ac157ad",
            "b1c5f32ff7d94d6587324ed659470209",
            "3e10bd64bbee4963b95b177d72121cdc",
            "d03812c9f17246c594b5d0bd565d74fa",
            "915c6c79f1404c819725a5ed49aad4e2",
            "30b25ebd825547c19e25bad4d87c2265",
            "61e5c2bab34e415ab9d42f6e6f2b3ff8",
            "fbf40b5f03d64d638f3e665f8e4d3209",
            "d7e3014bd9f844b3a7443b69a05f63d7",
            "61490fcc296e417fbd71d3fb3810d70f"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15333d704d3c48e5ae680c9a31eeec57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 train loss: 1.2994360433427323\n",
            "1 test  loss: 0.6328229027908348\n",
            "2 train loss: 0.6858818738845899\n",
            "2 test  loss: 0.6175296211647383\n",
            "3 train loss: 0.6380369050846338\n",
            "3 test  loss: 0.579935902869861\n",
            "4 train loss: 0.5644301766399511\n",
            "4 test  loss: 0.644380071815888\n",
            "5 train loss: 0.583355779952459\n",
            "5 test  loss: 0.5787385530792635\n",
            "6 train loss: 0.5522904843190825\n",
            "6 test  loss: 0.6140764700143841\n",
            "7 train loss: 0.5485536325848773\n",
            "7 test  loss: 0.5687570942249582\n",
            "8 train loss: 0.629583156478932\n",
            "8 test  loss: 0.5586322266783621\n",
            "9 train loss: 0.5033579437881307\n",
            "9 test  loss: 0.4986700920160506\n",
            "10 train loss: 0.4684898266874599\n",
            "10 test  loss: 0.5430756408826692\n",
            "11 train loss: 0.4384515616920398\n",
            "11 test  loss: 0.5222941871939555\n",
            "12 train loss: 0.4153020094513439\n",
            "12 test  loss: 0.4485664107044274\n",
            "13 train loss: 0.40885746181232846\n",
            "13 test  loss: 0.5064517385737384\n",
            "14 train loss: 0.44455169755522195\n",
            "14 test  loss: 0.501035626730083\n",
            "15 train loss: 0.3738041002813685\n",
            "15 test  loss: 0.43188713455762795\n",
            "16 train loss: 0.38252817619290985\n",
            "16 test  loss: 0.4051791364165744\n",
            "17 train loss: 0.38172881294919797\n",
            "17 test  loss: 0.4371799815750869\n",
            "18 train loss: 0.3704689545453494\n",
            "18 test  loss: 0.5580256136137481\n",
            "19 train loss: 0.36722456139890947\n",
            "19 test  loss: 0.40990406028398174\n",
            "20 train loss: 0.36432974651929656\n",
            "20 test  loss: 0.6600688615985157\n",
            "21 train loss: 0.377250958999457\n",
            "21 test  loss: 0.4445422293854741\n",
            "22 train loss: 0.367344273671254\n",
            "22 test  loss: 0.41700051486689327\n",
            "23 train loss: 0.4790682691010545\n",
            "23 test  loss: 0.468232663191948\n",
            "24 train loss: 0.4609858724091471\n",
            "24 test  loss: 0.4240889553406417\n",
            "25 train loss: 0.3243473592129192\n",
            "25 test  loss: 0.3200659761310931\n",
            "26 train loss: 0.3098305119456572\n",
            "26 test  loss: 0.38005223091308393\n",
            "27 train loss: 0.31052725897624667\n",
            "27 test  loss: 0.31001710306355723\n",
            "28 train loss: 0.3019041873450262\n",
            "28 test  loss: 0.3327036628624066\n",
            "29 train loss: 0.2966041254919703\n",
            "29 test  loss: 0.37177266109802254\n",
            "30 train loss: 0.3146497672738541\n",
            "30 test  loss: 0.4472577958742678\n",
            "31 train loss: 0.29833673171819475\n",
            "31 test  loss: 0.4611988150907931\n",
            "32 train loss: 0.29029100144851955\n",
            "32 test  loss: 0.38096340106892346\n",
            "33 train loss: 0.27069495564077706\n",
            "33 test  loss: 0.41052998524707573\n",
            "34 train loss: 0.2959193553042738\n",
            "34 test  loss: 0.3394818812492709\n",
            "35 train loss: 0.2714129295476769\n",
            "35 test  loss: 0.2647246223448704\n",
            "36 train loss: 0.2864242742832036\n",
            "36 test  loss: 0.42941580217194325\n",
            "37 train loss: 0.3938271204284436\n",
            "37 test  loss: 0.5182205669987238\n",
            "38 train loss: 0.3232206672843431\n",
            "38 test  loss: 0.3894309364060279\n",
            "39 train loss: 0.2678231784268317\n",
            "39 test  loss: 0.2848497714643324\n",
            "40 train loss: 0.28453706763636083\n",
            "40 test  loss: 0.31117234205847744\n",
            "41 train loss: 0.25737776715518723\n",
            "41 test  loss: 0.25943734019170195\n",
            "42 train loss: 0.3111494922498861\n",
            "42 test  loss: 0.3885460229845358\n",
            "43 train loss: 0.2931684536736894\n",
            "43 test  loss: 0.4105612981202684\n",
            "44 train loss: 0.29478407339326934\n",
            "44 test  loss: 0.2921979428746425\n",
            "45 train loss: 0.3578399179077675\n",
            "45 test  loss: 0.306742491762962\n",
            "46 train loss: 0.2807157199806794\n",
            "46 test  loss: 0.2870259202819556\n",
            "47 train loss: 0.352105812682849\n",
            "47 test  loss: 0.27389033624619263\n",
            "48 train loss: 0.2997687373893381\n",
            "48 test  loss: 0.31772474590213745\n",
            "49 train loss: 0.26939417369303914\n",
            "49 test  loss: 0.32748846360441464\n",
            "50 train loss: 0.24912866801751665\n",
            "50 test  loss: 0.3272406687463034\n",
            "51 train loss: 0.2679509623120858\n",
            "51 test  loss: 0.2845885152554917\n",
            "52 train loss: 0.31885864743132575\n",
            "52 test  loss: 0.28627223245641886\n",
            "53 train loss: 0.3440530749507378\n",
            "53 test  loss: 0.32100018003203507\n",
            "54 train loss: 0.3062371725157757\n",
            "54 test  loss: 0.27964179149262514\n",
            "55 train loss: 0.27565806470390103\n",
            "55 test  loss: 0.27912798422887175\n",
            "56 train loss: 0.36197590884116343\n",
            "56 test  loss: 0.2899670974425458\n",
            "57 train loss: 0.2570978076832315\n",
            "57 test  loss: 0.3111049524399487\n",
            "58 train loss: 0.29214753649020136\n",
            "58 test  loss: 0.3338759742242511\n",
            "59 train loss: 0.28776167511815404\n",
            "59 test  loss: 0.29280418891409954\n",
            "60 train loss: 0.26015528346488526\n",
            "60 test  loss: 0.2641550535083581\n",
            "61 train loss: 0.26117392074973217\n",
            "61 test  loss: 0.3014824241087348\n",
            "62 train loss: 0.28693889397799044\n",
            "62 test  loss: 0.2800654586463074\n",
            "63 train loss: 0.2805665376957366\n",
            "63 test  loss: 0.3872340323495771\n",
            "64 train loss: 0.2802284454291497\n",
            "64 test  loss: 0.3575917412192786\n",
            "65 train loss: 0.23162976406002006\n",
            "65 test  loss: 0.32846842926629016\n",
            "66 train loss: 0.24221083565111662\n",
            "66 test  loss: 0.3359394703069721\n",
            "67 train loss: 0.24157036607360427\n",
            "67 test  loss: 0.30510432981560776\n",
            "68 train loss: 0.30016284054329223\n",
            "68 test  loss: 0.39953974772682893\n",
            "69 train loss: 0.23176936994401387\n",
            "69 test  loss: 0.3063899732468315\n",
            "70 train loss: 0.26458740583380025\n",
            "70 test  loss: 0.3098742786669873\n",
            "71 train loss: 0.261608715732494\n",
            "71 test  loss: 0.3068865135885273\n",
            "72 train loss: 0.2947638757763796\n",
            "72 test  loss: 0.4577799923853313\n",
            "73 train loss: 0.2715236421302355\n",
            "73 test  loss: 0.3071655069292096\n",
            "74 train loss: 0.26330383361214593\n",
            "74 test  loss: 0.28322127882913783\n",
            "75 train loss: 0.23309654006097716\n",
            "75 test  loss: 0.22289030690149358\n",
            "76 train loss: 0.2266935933392441\n",
            "76 test  loss: 0.2527568030514767\n",
            "77 train loss: 0.2694243182068106\n",
            "77 test  loss: 0.30514030486047355\n",
            "78 train loss: 0.2735034211644918\n",
            "78 test  loss: 0.2442471076084916\n",
            "79 train loss: 0.3162898962135256\n",
            "79 test  loss: 0.3427201571311128\n",
            "80 train loss: 0.28390015542167774\n",
            "80 test  loss: 0.26874493841357067\n",
            "81 train loss: 0.2431727951326084\n",
            "81 test  loss: 0.23421369549154109\n",
            "82 train loss: 0.275586734051129\n",
            "82 test  loss: 0.237750128905194\n",
            "83 train loss: 0.25510277916721225\n",
            "83 test  loss: 0.26343693260183193\n",
            "84 train loss: 0.2502210674560749\n",
            "84 test  loss: 0.3608274364202885\n",
            "85 train loss: 0.24364275236877195\n",
            "85 test  loss: 0.2578369360788555\n",
            "86 train loss: 0.2609502205594134\n",
            "86 test  loss: 0.3718063010707924\n",
            "87 train loss: 0.27448800737981016\n",
            "87 test  loss: 0.30327741016322113\n",
            "88 train loss: 0.28193903920273894\n",
            "88 test  loss: 0.26487001496226786\n",
            "89 train loss: 0.2362659740565497\n",
            "89 test  loss: 0.28706735985218096\n",
            "90 train loss: 0.2590362411255501\n",
            "90 test  loss: 0.4321183337585478\n",
            "91 train loss: 0.243059197876782\n",
            "91 test  loss: 0.2548274457059978\n",
            "92 train loss: 0.2606430982275783\n",
            "92 test  loss: 0.33213841863165217\n",
            "93 train loss: 0.23467982855653038\n",
            "93 test  loss: 0.24392778709326465\n",
            "94 train loss: 0.23151115000750835\n",
            "94 test  loss: 0.29770879094447245\n",
            "95 train loss: 0.23564539057657743\n",
            "95 test  loss: 0.2668360673822603\n",
            "96 train loss: 0.24197040268009826\n",
            "96 test  loss: 0.3316346723906175\n",
            "97 train loss: 0.252094190945134\n",
            "97 test  loss: 0.29895824988171504\n",
            "98 train loss: 0.256209615492364\n",
            "98 test  loss: 0.2626631820256758\n",
            "99 train loss: 0.26099870706462874\n",
            "99 test  loss: 0.2485439860385789\n",
            "100 train loss: 0.26463065906095884\n",
            "100 test  loss: 0.30498795790808064\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 100\n",
        "pbar = tqdm(range(1, num_epochs + 1))\n",
        "\n",
        "for epoch in pbar:\n",
        "    train_loss, test_loss = 0.0, 0.0\n",
        "\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(X_batch)\n",
        "        loss = criterion(predictions, y_batch)\n",
        "        model.backward(X_batch, criterion.backward(predictions, y_batch))\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss * X_batch.shape[0]\n",
        "\n",
        "    model.eval()\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        predictions = model(X_batch)\n",
        "        loss = criterion(predictions, y_batch)\n",
        "        test_loss += loss * X_batch.shape[0]\n",
        "\n",
        "    train_loss /= train_loader.num_samples()\n",
        "    test_loss /= test_loader.num_samples()\n",
        "    print(f\"{epoch} train loss:\", train_loss)\n",
        "    print(f\"{epoch} test  loss:\", test_loss)\n",
        "    # pbar.set_postfix({'train loss': train_loss, 'test loss': test_loss})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wow, it works!!!"
      ],
      "metadata": {
        "id": "alIonSJpme2j"
      },
      "id": "alIonSJpme2j"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15333d704d3c48e5ae680c9a31eeec57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01a04f17987642efa7f8c37c0ac157ad",
              "IPY_MODEL_b1c5f32ff7d94d6587324ed659470209",
              "IPY_MODEL_3e10bd64bbee4963b95b177d72121cdc"
            ],
            "layout": "IPY_MODEL_d03812c9f17246c594b5d0bd565d74fa"
          }
        },
        "01a04f17987642efa7f8c37c0ac157ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_915c6c79f1404c819725a5ed49aad4e2",
            "placeholder": "​",
            "style": "IPY_MODEL_30b25ebd825547c19e25bad4d87c2265",
            "value": "100%"
          }
        },
        "b1c5f32ff7d94d6587324ed659470209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61e5c2bab34e415ab9d42f6e6f2b3ff8",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbf40b5f03d64d638f3e665f8e4d3209",
            "value": 100
          }
        },
        "3e10bd64bbee4963b95b177d72121cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7e3014bd9f844b3a7443b69a05f63d7",
            "placeholder": "​",
            "style": "IPY_MODEL_61490fcc296e417fbd71d3fb3810d70f",
            "value": " 100/100 [00:03&lt;00:00, 29.58it/s]"
          }
        },
        "d03812c9f17246c594b5d0bd565d74fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "915c6c79f1404c819725a5ed49aad4e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30b25ebd825547c19e25bad4d87c2265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61e5c2bab34e415ab9d42f6e6f2b3ff8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbf40b5f03d64d638f3e665f8e4d3209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7e3014bd9f844b3a7443b69a05f63d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61490fcc296e417fbd71d3fb3810d70f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}